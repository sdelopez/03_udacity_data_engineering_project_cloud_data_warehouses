{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# install python s3fs package to read s3 bucket as filesystem\n",
    "!pip install s3fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "import json\n",
    "import s3fs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# 1. Load DWH Params from a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Param</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DWH_CLUSTER_TYPE</td>\n",
       "      <td>multi-node</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DWH_NUM_NODES</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DWH_NODE_TYPE</td>\n",
       "      <td>dc2.large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DWH_CLUSTER_IDENTIFIER</td>\n",
       "      <td>dwhCluster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DWH_DB</td>\n",
       "      <td>dwh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DWH_DB_USER</td>\n",
       "      <td>dwhuser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DWH_DB_PASSWORD</td>\n",
       "      <td>Passw0rd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DWH_PORT</td>\n",
       "      <td>5439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DWH_IAM_ROLE_NAME</td>\n",
       "      <td>dwhRole</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Param       Value\n",
       "0        DWH_CLUSTER_TYPE  multi-node\n",
       "1           DWH_NUM_NODES           4\n",
       "2           DWH_NODE_TYPE   dc2.large\n",
       "3  DWH_CLUSTER_IDENTIFIER  dwhCluster\n",
       "4                  DWH_DB         dwh\n",
       "5             DWH_DB_USER     dwhuser\n",
       "6         DWH_DB_PASSWORD    Passw0rd\n",
       "7                DWH_PORT        5439\n",
       "8       DWH_IAM_ROLE_NAME     dwhRole"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "config.read_file(open('dwh.cfg'))\n",
    "\n",
    "KEY                    = config.get('AWS','KEY')\n",
    "SECRET                 = config.get('AWS','SECRET')\n",
    "\n",
    "DWH_CLUSTER_TYPE       = config.get(\"DWH\",\"DWH_CLUSTER_TYPE\")\n",
    "DWH_NUM_NODES          = config.get(\"DWH\",\"DWH_NUM_NODES\")\n",
    "DWH_NODE_TYPE          = config.get(\"DWH\",\"DWH_NODE_TYPE\")\n",
    "\n",
    "DWH_CLUSTER_IDENTIFIER = config.get(\"DWH\",\"DWH_CLUSTER_IDENTIFIER\")\n",
    "DWH_DB                 = config.get(\"DWH\",\"DWH_DB\")\n",
    "DWH_DB_USER            = config.get(\"DWH\",\"DWH_DB_USER\")\n",
    "DWH_DB_PASSWORD        = config.get(\"DWH\",\"DWH_DB_PASSWORD\")\n",
    "DWH_PORT               = config.get(\"DWH\",\"DWH_PORT\")\n",
    "\n",
    "DWH_IAM_ROLE_NAME      = config.get(\"DWH\", \"DWH_IAM_ROLE_NAME\")\n",
    "\n",
    "(DWH_DB_USER, DWH_DB_PASSWORD, DWH_DB)\n",
    "\n",
    "pd.DataFrame({\"Param\":\n",
    "                  [\"DWH_CLUSTER_TYPE\", \"DWH_NUM_NODES\", \"DWH_NODE_TYPE\", \"DWH_CLUSTER_IDENTIFIER\", \"DWH_DB\", \"DWH_DB_USER\", \"DWH_DB_PASSWORD\", \"DWH_PORT\", \"DWH_IAM_ROLE_NAME\"],\n",
    "              \"Value\":\n",
    "                  [DWH_CLUSTER_TYPE, DWH_NUM_NODES, DWH_NODE_TYPE, DWH_CLUSTER_IDENTIFIER, DWH_DB, DWH_DB_USER, DWH_DB_PASSWORD, DWH_PORT, DWH_IAM_ROLE_NAME]\n",
    "             })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# 2. Create clients for EC2, S3, IAM, and Redshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "ec2 = boto3.resource('ec2',\n",
    "                    region_name='us-west-2',\n",
    "                    aws_access_key_id = KEY,\n",
    "                    aws_secret_access_key = SECRET)\n",
    "\n",
    "s3 = boto3.resource('s3',\n",
    "                    region_name='us-west-2',\n",
    "                    aws_access_key_id = KEY,\n",
    "                    aws_secret_access_key = SECRET)\n",
    "\n",
    "iam = boto3.client('iam',\n",
    "                    region_name='us-west-2',\n",
    "                    aws_access_key_id = KEY,\n",
    "                    aws_secret_access_key = SECRET)\n",
    "\n",
    "redshift = boto3.client('redshift',\n",
    "                    region_name='us-west-2',\n",
    "                    aws_access_key_id = KEY,\n",
    "                    aws_secret_access_key = SECRET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# 3. Explore Sparkify data sources on S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# load S3 path for log, songs\n",
    "\n",
    "LOG_DATA=config.get('S3','LOG_DATA')\n",
    "LOG_JSONPATH=config.get('S3','LOG_JSONPATH')\n",
    "SONG_DATA=config.get('S3','SONG_DATA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'s3://udacity-dend/log-data'\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LOG_DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# connect to Sparkify S3 bucket\n",
    "sparkifyDbBucket =  s3.Bucket(\"udacity-dend\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['log-data/2018/11/2018-11-01-events.json',\n",
       " 'log-data/2018/11/2018-11-02-events.json',\n",
       " 'log-data/2018/11/2018-11-03-events.json',\n",
       " 'log-data/2018/11/2018-11-04-events.json',\n",
       " 'log-data/2018/11/2018-11-05-events.json',\n",
       " 'log-data/2018/11/2018-11-06-events.json',\n",
       " 'log-data/2018/11/2018-11-07-events.json',\n",
       " 'log-data/2018/11/2018-11-08-events.json',\n",
       " 'log-data/2018/11/2018-11-09-events.json']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the list of log data file from S3\n",
    "log_data_files = [filename.key for filename in sparkifyDbBucket.objects.filter(Prefix='log-data')]\n",
    "log_data_files[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# read one event-log file from S3 bucket\n",
    "\n",
    "df_log = pd.read_json('s3://udacity-dend/{}'.format(log_data_files[1]), lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15 entries, 0 to 14\n",
      "Data columns (total 18 columns):\n",
      "artist           11 non-null object\n",
      "auth             15 non-null object\n",
      "firstName        15 non-null object\n",
      "gender           15 non-null object\n",
      "itemInSession    15 non-null int64\n",
      "lastName         15 non-null object\n",
      "length           11 non-null float64\n",
      "level            15 non-null object\n",
      "location         15 non-null object\n",
      "method           15 non-null object\n",
      "page             15 non-null object\n",
      "registration     15 non-null int64\n",
      "sessionId        15 non-null int64\n",
      "song             11 non-null object\n",
      "status           15 non-null int64\n",
      "ts               15 non-null int64\n",
      "userAgent        15 non-null object\n",
      "userId           15 non-null int64\n",
      "dtypes: float64(1), int64(6), object(11)\n",
      "memory usage: 2.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# check columns name to create Field for staging tables\n",
    "df_log.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'s3://udacity-dend/song-data'\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SONG_DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# get the list of song data file from S3 - File is big so be patient\n",
    "song_data_files = [filename.key for filename in sparkifyDbBucket.objects.filter(Prefix='song-data')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "385253"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check number of song to load to staging tables\n",
    "len(song_data_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['song-data/',\n",
       " 'song-data/A/A/A/TRAAAAK128F9318786.json',\n",
       " 'song-data/A/A/A/TRAAAAV128F421A322.json',\n",
       " 'song-data/A/A/A/TRAAABD128F429CF47.json',\n",
       " 'song-data/A/A/A/TRAAACN128F9355673.json',\n",
       " 'song-data/A/A/A/TRAAAEA128F935A30D.json',\n",
       " 'song-data/A/A/A/TRAAAED128E0783FAB.json',\n",
       " 'song-data/A/A/A/TRAAAEM128F93347B9.json',\n",
       " 'song-data/A/A/A/TRAAAEW128F42930C0.json',\n",
       " 'song-data/A/A/A/TRAAAFD128F92F423A.json']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check song file list\n",
    "song_data_files[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# read one son-data file from S3 bucket\n",
    "\n",
    "df_song = pd.read_json('s3://udacity-dend/{}'.format(song_data_files[1]), lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1 entries, 0 to 0\n",
      "Data columns (total 10 columns):\n",
      "artist_id           1 non-null object\n",
      "artist_latitude     0 non-null float64\n",
      "artist_location     1 non-null object\n",
      "artist_longitude    0 non-null float64\n",
      "artist_name         1 non-null object\n",
      "duration            1 non-null float64\n",
      "num_songs           1 non-null int64\n",
      "song_id             1 non-null object\n",
      "title               1 non-null object\n",
      "year                1 non-null int64\n",
      "dtypes: float64(3), int64(2), object(5)\n",
      "memory usage: 160.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "# check song-data columns name for staging table fields\n",
    "df_song.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>auth</th>\n",
       "      <th>firstName</th>\n",
       "      <th>gender</th>\n",
       "      <th>itemInSession</th>\n",
       "      <th>lastName</th>\n",
       "      <th>length</th>\n",
       "      <th>level</th>\n",
       "      <th>location</th>\n",
       "      <th>method</th>\n",
       "      <th>page</th>\n",
       "      <th>registration</th>\n",
       "      <th>sessionId</th>\n",
       "      <th>song</th>\n",
       "      <th>status</th>\n",
       "      <th>ts</th>\n",
       "      <th>userAgent</th>\n",
       "      <th>userId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Walter</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>Frye</td>\n",
       "      <td>NaN</td>\n",
       "      <td>free</td>\n",
       "      <td>San Francisco-Oakland-Hayward, CA</td>\n",
       "      <td>GET</td>\n",
       "      <td>Home</td>\n",
       "      <td>1540919166796</td>\n",
       "      <td>38</td>\n",
       "      <td>None</td>\n",
       "      <td>200</td>\n",
       "      <td>1541105830796</td>\n",
       "      <td>\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Kaylee</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>Summers</td>\n",
       "      <td>NaN</td>\n",
       "      <td>free</td>\n",
       "      <td>Phoenix-Mesa-Scottsdale, AZ</td>\n",
       "      <td>GET</td>\n",
       "      <td>Home</td>\n",
       "      <td>1540344794796</td>\n",
       "      <td>139</td>\n",
       "      <td>None</td>\n",
       "      <td>200</td>\n",
       "      <td>1541106106796</td>\n",
       "      <td>\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Des'ree</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Kaylee</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>Summers</td>\n",
       "      <td>246.30812</td>\n",
       "      <td>free</td>\n",
       "      <td>Phoenix-Mesa-Scottsdale, AZ</td>\n",
       "      <td>PUT</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>1540344794796</td>\n",
       "      <td>139</td>\n",
       "      <td>You Gotta Be</td>\n",
       "      <td>200</td>\n",
       "      <td>1541106106796</td>\n",
       "      <td>\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Kaylee</td>\n",
       "      <td>F</td>\n",
       "      <td>2</td>\n",
       "      <td>Summers</td>\n",
       "      <td>NaN</td>\n",
       "      <td>free</td>\n",
       "      <td>Phoenix-Mesa-Scottsdale, AZ</td>\n",
       "      <td>GET</td>\n",
       "      <td>Upgrade</td>\n",
       "      <td>1540344794796</td>\n",
       "      <td>139</td>\n",
       "      <td>None</td>\n",
       "      <td>200</td>\n",
       "      <td>1541106132796</td>\n",
       "      <td>\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mr Oizo</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Kaylee</td>\n",
       "      <td>F</td>\n",
       "      <td>3</td>\n",
       "      <td>Summers</td>\n",
       "      <td>144.03873</td>\n",
       "      <td>free</td>\n",
       "      <td>Phoenix-Mesa-Scottsdale, AZ</td>\n",
       "      <td>PUT</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>1540344794796</td>\n",
       "      <td>139</td>\n",
       "      <td>Flat 55</td>\n",
       "      <td>200</td>\n",
       "      <td>1541106352796</td>\n",
       "      <td>\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    artist       auth firstName gender  itemInSession lastName     length  \\\n",
       "0     None  Logged In    Walter      M              0     Frye        NaN   \n",
       "1     None  Logged In    Kaylee      F              0  Summers        NaN   \n",
       "2  Des'ree  Logged In    Kaylee      F              1  Summers  246.30812   \n",
       "3     None  Logged In    Kaylee      F              2  Summers        NaN   \n",
       "4  Mr Oizo  Logged In    Kaylee      F              3  Summers  144.03873   \n",
       "\n",
       "  level                           location method      page   registration  \\\n",
       "0  free  San Francisco-Oakland-Hayward, CA    GET      Home  1540919166796   \n",
       "1  free        Phoenix-Mesa-Scottsdale, AZ    GET      Home  1540344794796   \n",
       "2  free        Phoenix-Mesa-Scottsdale, AZ    PUT  NextSong  1540344794796   \n",
       "3  free        Phoenix-Mesa-Scottsdale, AZ    GET   Upgrade  1540344794796   \n",
       "4  free        Phoenix-Mesa-Scottsdale, AZ    PUT  NextSong  1540344794796   \n",
       "\n",
       "   sessionId          song  status             ts  \\\n",
       "0         38          None     200  1541105830796   \n",
       "1        139          None     200  1541106106796   \n",
       "2        139  You Gotta Be     200  1541106106796   \n",
       "3        139          None     200  1541106132796   \n",
       "4        139       Flat 55     200  1541106352796   \n",
       "\n",
       "                                           userAgent  userId  \n",
       "0  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...      39  \n",
       "1  \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...       8  \n",
       "2  \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...       8  \n",
       "3  \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...       8  \n",
       "4  \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...       8  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_song.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# read S3 bucket - log_json_path - define json file mapping to read from S3 for loading staging tables\n",
    "\n",
    "df = pd.read_json('s3://udacity-dend/log_json_path.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            $['artist']\n",
       "1              $['auth']\n",
       "2         $['firstName']\n",
       "3            $['gender']\n",
       "4     $['itemInSession']\n",
       "5          $['lastName']\n",
       "6            $['length']\n",
       "7             $['level']\n",
       "8          $['location']\n",
       "9            $['method']\n",
       "10             $['page']\n",
       "11     $['registration']\n",
       "12        $['sessionId']\n",
       "13             $['song']\n",
       "14           $['status']\n",
       "15               $['ts']\n",
       "16        $['userAgent']\n",
       "17           $['userId']\n",
       "Name: jsonpaths, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.jsonpaths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# 4. Configure AWS Redshit Cluster - Infrastructure as Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 4.1: IAM ROLE\n",
    "- Create an IAM Role that makes Redshift able to access S3 bucket (ReadOnly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1 Creating a new IAM Role\n",
      "An error occurred (EntityAlreadyExists) when calling the CreateRole operation: Role with name dwhRole already exists.\n"
     ]
    }
   ],
   "source": [
    "# Create the IAM role\n",
    "try:\n",
    "    print('4.1.1 Creating a new IAM Role')\n",
    "    dwhRole = iam.create_role(\n",
    "                                Path = '/',\n",
    "                                RoleName = DWH_IAM_ROLE_NAME,\n",
    "                                Description = 'Allows Redshift clusters to call AWS services on your behalf.',\n",
    "                                AssumeRolePolicyDocument = json.dumps(\n",
    "                                                                    {\n",
    "                                                                        'Statement' : [{\n",
    "                                                                                        'Action' : 'sts:AssumeRole',\n",
    "                                                                                        'Effect' : 'Allow',\n",
    "                                                                                        'Principal' : {'Service' : 'redshift.amazonaws.com'}\n",
    "                                                                                        }],\n",
    "                                                                        'Version' : '2012-10-17'\n",
    "                                                                    }\n",
    "                                                                    )\n",
    "\n",
    "                            )\n",
    "    \n",
    "\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2 Attaching Policy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Attach Policy\n",
    "print('4.1.2 Attaching Policy')\n",
    "iam.attach_role_policy(RoleName = DWH_IAM_ROLE_NAME,\n",
    "                        PolicyArn = 'arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess',\n",
    "                        )['ResponseMetadata']['HTTPStatusCode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3 Get the IAM role ARN\n",
      "arn:aws:iam::964592634597:role/dwhRole\n"
     ]
    }
   ],
   "source": [
    "# Get and print the IAM role ARN\n",
    "print('4.1.3 Get the IAM role ARN')\n",
    "roleArn = iam.get_role(RoleName = DWH_IAM_ROLE_NAME)['Role']['Arn']\n",
    "\n",
    "print(roleArn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 4.2 Redshift Cluster\n",
    "\n",
    "- Create a RedShift Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create a RedShift Cluster\n",
    "try:\n",
    "    response = redshift.create_cluster(        \n",
    "        # add parameters for hardware\n",
    "        ClusterType = DWH_CLUSTER_TYPE,\n",
    "        NodeType = DWH_NODE_TYPE,\n",
    "        NumberOfNodes = int(DWH_NUM_NODES),\n",
    "\n",
    "        # add parameters for identifiers & credentials\n",
    "        DBName = DWH_DB,\n",
    "        ClusterIdentifier = DWH_CLUSTER_IDENTIFIER,\n",
    "        MasterUsername = DWH_DB_USER,\n",
    "        MasterUserPassword = DWH_DB_PASSWORD,\n",
    "        \n",
    "        # add parameter for role (to allow s3 access)\n",
    "        IamRoles = [roleArn]\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 4.2.1 *Check* the cluster to see its status\n",
    "- run this block several times until the cluster status becomes `Available`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ClusterIdentifier</td>\n",
       "      <td>dwhcluster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NodeType</td>\n",
       "      <td>dc2.large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ClusterStatus</td>\n",
       "      <td>available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MasterUsername</td>\n",
       "      <td>dwhuser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DBName</td>\n",
       "      <td>dwh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Endpoint</td>\n",
       "      <td>{'Address': 'dwhcluster.cnl5ezt8wl23.us-west-2.redshift.amazonaws.com', 'Port': 5439}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>VpcId</td>\n",
       "      <td>vpc-a8e792d0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NumberOfNodes</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Key  \\\n",
       "0  ClusterIdentifier   \n",
       "1  NodeType            \n",
       "2  ClusterStatus       \n",
       "3  MasterUsername      \n",
       "4  DBName              \n",
       "5  Endpoint            \n",
       "6  VpcId               \n",
       "7  NumberOfNodes       \n",
       "\n",
       "                                                                                   Value  \n",
       "0  dwhcluster                                                                             \n",
       "1  dc2.large                                                                              \n",
       "2  available                                                                              \n",
       "3  dwhuser                                                                                \n",
       "4  dwh                                                                                    \n",
       "5  {'Address': 'dwhcluster.cnl5ezt8wl23.us-west-2.redshift.amazonaws.com', 'Port': 5439}  \n",
       "6  vpc-a8e792d0                                                                           \n",
       "7  4                                                                                      "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "\n",
    "\n",
    "def prettyRedshiftProps(props):\n",
    "    pd.set_option('display.max_colwidth', -1)\n",
    "    keysToShow = [\"ClusterIdentifier\", \"NodeType\", \"ClusterStatus\", \"MasterUsername\", \"DBName\", \"Endpoint\", \"NumberOfNodes\", 'VpcId']\n",
    "    x = [(k, v) for k,v in props.items() if k in keysToShow]\n",
    "    return pd.DataFrame(data=x, columns=[\"Key\", \"Value\"])\n",
    "\n",
    "myClusterProps = redshift.describe_clusters(ClusterIdentifier=DWH_CLUSTER_IDENTIFIER)['Clusters'][0]\n",
    "prettyRedshiftProps(myClusterProps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "<h3> 4.2.2 Set the cluster <font color='red'> endpoint and role ARN </font> </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DWH_ENDPOINT ::  dwhcluster.cnl5ezt8wl23.us-west-2.redshift.amazonaws.com\n",
      "DWH_ROLE_ARN ::  arn:aws:iam::964592634597:role/dwhRole\n"
     ]
    }
   ],
   "source": [
    "# DWH_ENDPOINT must be set in dwh.cfg in [CLUSTER]HOST=\n",
    "# DWH_ROLE_ARN must be set in dwh.cfg in [IAM_ROLE]ARN=\n",
    "DWH_ENDPOINT = myClusterProps['Endpoint']['Address']\n",
    "DWH_ROLE_ARN = myClusterProps['IamRoles'][0]['IamRoleArn']\n",
    "print(\"DWH_ENDPOINT :: \", DWH_ENDPOINT )\n",
    "print(\"DWH_ROLE_ARN :: \", DWH_ROLE_ARN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "<h3> to run correctly the **create_tables.py** and **etl.py** scripts <font color='red'> endpoint and role ARN </font> </h3>\n",
    "Set DWH_ENDPOINT and DWH_ROLE_ARN for [CLUSTER] in dwh.cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 4.3 Open an incoming  TCP port to access the cluster ednpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ec2.SecurityGroup(id='sg-7accc02a')\n"
     ]
    }
   ],
   "source": [
    "vpc = ec2.Vpc(id=myClusterProps['VpcId'])\n",
    "defaultSg = list(vpc.security_groups.all())[0]\n",
    "print(defaultSg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ec2.SecurityGroup(id='sg-7accc02a')\n",
      "An error occurred (InvalidPermission.Duplicate) when calling the AuthorizeSecurityGroupIngress operation: the specified rule \"peer: 0.0.0.0/0, TCP, from port: 5439, to port: 5439, ALLOW\" already exists\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    vpc = ec2.Vpc(id=myClusterProps['VpcId'])\n",
    "    defaultSg = list(vpc.security_groups.all())[0]\n",
    "    print(defaultSg)\n",
    "    \n",
    "    defaultSg.authorize_ingress(\n",
    "        GroupName= defaultSg.group_name,  # TODO: fill out\n",
    "        CidrIp='0.0.0.0/0',  # TODO: fill out\n",
    "        IpProtocol='TCP',  # TODO: fill out\n",
    "        FromPort=int(DWH_PORT),\n",
    "        ToPort=int(DWH_PORT)\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 4.4 Check connection to the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postgresql://dwhuser:Passw0rd@dwhcluster.cnl5ezt8wl23.us-west-2.redshift.amazonaws.com:5439/dwh\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Connected: dwhuser@dwh'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn_string=\"postgresql://{}:{}@{}:{}/{}\".format(DWH_DB_USER, DWH_DB_PASSWORD, DWH_ENDPOINT, DWH_PORT,DWH_DB)\n",
    "print(conn_string)\n",
    "%sql $conn_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# 5. Sparkify ETL Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 5.1 Create  Staging, Facts and Dimension Tables in Redshift DWH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Run python script to create  Staging, Facts and Dimension Tables in Redshift DWH or open a Shell Terminal to run the following script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# run python script to create  Staging, Facts and Dimension Tables in Redshift DWH\n",
    "# or open a Shell Terminal to run the following script\n",
    "!./create_tables.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 5.2 Run ETL pipelines to Extract raw data to staging tables, Transform and Load data to Facts & Dimension tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Run python script to process ETL pipleines to Extract raw data to staging tables, Transform and Load data to Facts & Dimension tables  \n",
    "or open a Shell Terminal to run the following script  \n",
    "ETL process is lengthy so please be patient -> **up or more than 1 hour to complete** to load the full song data to staging table.  \n",
    "\n",
    "For checking development/checking purpose, we can reduce the number song data to load to staging table by using only a subset of song data :  \n",
    ". full song data **s3://udacity-dend/song_data** (use **SONG_DATA** in dwh.cg)    \n",
    ". subset of song data **s3://udacity-dend/song_data/A/A** (use **SONG_DATA_SUBSET** in dwh.cg)   \n",
    "\n",
    "see question on Knowledge center [COPY Command runtime over 2 hours](https://knowledge.udacity.com/questions/113908)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Query time on Redshift for ETL Process on full Song data > 1 hour\n",
    "# For developement purpose, use SONG_DATA_SUBSET instead of SONG_DATA in sql_queries.py\n",
    "# before running etl.py\n",
    "!./etl.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# 6. Check that DWH tables were populated correctly by ETL process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 6.1 Check Staging Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "count staging events records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://dwhuser:***@dwhcluster.cnl5ezt8wl23.us-west-2.redshift.amazonaws.com:5439/dwh\n",
      "1 rows affected.\n",
      "Returning data to local variable stag_event\n"
     ]
    }
   ],
   "source": [
    "%%sql\n",
    "stag_event << select count(*) as stag_event from staging_events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "count staging records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://dwhuser:***@dwhcluster.cnl5ezt8wl23.us-west-2.redshift.amazonaws.com:5439/dwh\n",
      "1 rows affected.\n",
      "Returning data to local variable stag_song\n"
     ]
    }
   ],
   "source": [
    "%%sql\n",
    "stag_song << select count(*) as stag_song from staging_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Staging User = +------------+\n",
      "| stag_event |\n",
      "+------------+\n",
      "|    8056    |\n",
      "+------------+\n",
      "Count Staging Song = +-----------+\n",
      "| stag_song |\n",
      "+-----------+\n",
      "|   385252  |\n",
      "+-----------+\n"
     ]
    }
   ],
   "source": [
    "# print count values for all  tables\n",
    "print(\"Count Staging User = {}\".format(stag_event))\n",
    "print(\"Count Staging Song = {}\".format(stag_song))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 6.2 Check Fact and Dimension Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "count fact_songplay records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://dwhuser:***@dwhcluster.cnl5ezt8wl23.us-west-2.redshift.amazonaws.com:5439/dwh\n",
      "1 rows affected.\n",
      "Returning data to local variable count_songplay\n"
     ]
    }
   ],
   "source": [
    "%%sql\n",
    "count_songplay << select count(*) as total_songplay from fact_songplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "count dim_users records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://dwhuser:***@dwhcluster.cnl5ezt8wl23.us-west-2.redshift.amazonaws.com:5439/dwh\n",
      "1 rows affected.\n",
      "Returning data to local variable count_user\n"
     ]
    }
   ],
   "source": [
    "%%sql\n",
    "count_user << select count(*) as total_user from dim_user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "count dim_song records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://dwhuser:***@dwhcluster.cnl5ezt8wl23.us-west-2.redshift.amazonaws.com:5439/dwh\n",
      "1 rows affected.\n",
      "Returning data to local variable count_song\n"
     ]
    }
   ],
   "source": [
    "%%sql\n",
    "count_song << select count(*) as total_song from dim_song"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "count dim_artist records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://dwhuser:***@dwhcluster.cnl5ezt8wl23.us-west-2.redshift.amazonaws.com:5439/dwh\n",
      "1 rows affected.\n",
      "Returning data to local variable count_artist\n"
     ]
    }
   ],
   "source": [
    "%%sql\n",
    "count_artist << select count(*) as total_artist from dim_artist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "count dim_time records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://dwhuser:***@dwhcluster.cnl5ezt8wl23.us-west-2.redshift.amazonaws.com:5439/dwh\n",
      "1 rows affected.\n",
      "Returning data to local variable count_time\n"
     ]
    }
   ],
   "source": [
    "%%sql\n",
    "count_time << select count(*) as total_time from dim_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "print count values for all  tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Songplay = +----------------+\n",
      "| total_songplay |\n",
      "+----------------+\n",
      "|      6929      |\n",
      "+----------------+\n",
      "Count User = +------------+\n",
      "| total_user |\n",
      "+------------+\n",
      "|    105     |\n",
      "+------------+\n",
      "Count Song = +------------+\n",
      "| total_song |\n",
      "+------------+\n",
      "|   384995   |\n",
      "+------------+\n",
      "Count Artist = +--------------+\n",
      "| total_artist |\n",
      "+--------------+\n",
      "|    45266     |\n",
      "+--------------+\n",
      "Count Time = +------------+\n",
      "| total_time |\n",
      "+------------+\n",
      "|    8023    |\n",
      "+------------+\n"
     ]
    }
   ],
   "source": [
    "print(\"Count Songplay = {}\".format(count_songplay))\n",
    "print(\"Count User = {}\".format(count_user))\n",
    "print(\"Count Song = {}\".format(count_song))\n",
    "print(\"Count Artist = {}\".format(count_artist))\n",
    "print(\"Count Time = {}\".format(count_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# 7. Clean AWS Redshift Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 7.1 Clean Redshift Cluster - DO NOT RUN THIS UNLESS YOU ARE SURE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cluster': {'ClusterIdentifier': 'dwhcluster',\n",
       "  'NodeType': 'dc2.large',\n",
       "  'ClusterStatus': 'deleting',\n",
       "  'ClusterAvailabilityStatus': 'Modifying',\n",
       "  'MasterUsername': 'dwhuser',\n",
       "  'DBName': 'dwh',\n",
       "  'Endpoint': {'Address': 'dwhcluster.cnl5ezt8wl23.us-west-2.redshift.amazonaws.com',\n",
       "   'Port': 5439},\n",
       "  'ClusterCreateTime': datetime.datetime(2020, 6, 7, 14, 42, 37, 811000, tzinfo=tzlocal()),\n",
       "  'AutomatedSnapshotRetentionPeriod': 1,\n",
       "  'ManualSnapshotRetentionPeriod': -1,\n",
       "  'ClusterSecurityGroups': [],\n",
       "  'VpcSecurityGroups': [{'VpcSecurityGroupId': 'sg-7accc02a',\n",
       "    'Status': 'active'}],\n",
       "  'ClusterParameterGroups': [{'ParameterGroupName': 'default.redshift-1.0',\n",
       "    'ParameterApplyStatus': 'in-sync'}],\n",
       "  'ClusterSubnetGroupName': 'default',\n",
       "  'VpcId': 'vpc-a8e792d0',\n",
       "  'AvailabilityZone': 'us-west-2b',\n",
       "  'PreferredMaintenanceWindow': 'sat:12:30-sat:13:00',\n",
       "  'PendingModifiedValues': {},\n",
       "  'ClusterVersion': '1.0',\n",
       "  'AllowVersionUpgrade': True,\n",
       "  'NumberOfNodes': 4,\n",
       "  'PubliclyAccessible': True,\n",
       "  'Encrypted': False,\n",
       "  'Tags': [],\n",
       "  'EnhancedVpcRouting': False,\n",
       "  'IamRoles': [{'IamRoleArn': 'arn:aws:iam::964592634597:role/dwhRole',\n",
       "    'ApplyStatus': 'in-sync'}],\n",
       "  'MaintenanceTrackName': 'current',\n",
       "  'DeferredMaintenanceWindows': [],\n",
       "  'NextMaintenanceWindowStartTime': datetime.datetime(2020, 6, 13, 12, 30, tzinfo=tzlocal())},\n",
       " 'ResponseMetadata': {'RequestId': '78b4cd29-1309-46cb-8bbe-4134a7380760',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '78b4cd29-1309-46cb-8bbe-4134a7380760',\n",
       "   'content-type': 'text/xml',\n",
       "   'content-length': '2382',\n",
       "   'vary': 'accept-encoding',\n",
       "   'date': 'Sun, 07 Jun 2020 16:40:21 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### CAREFUL!!\n",
    "#-- Uncomment & run to delete the created resources\n",
    "redshift.delete_cluster( ClusterIdentifier=DWH_CLUSTER_IDENTIFIER,  SkipFinalClusterSnapshot=True)\n",
    "#### CAREFUL!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "run this block several times until the cluster really deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "ename": "ClusterNotFoundFault",
     "evalue": "An error occurred (ClusterNotFound) when calling the DescribeClusters operation: Cluster dwhcluster not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClusterNotFoundFault\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-9b3202a2945e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmyClusterProps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mredshift\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe_clusters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mClusterIdentifier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDWH_CLUSTER_IDENTIFIER\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Clusters'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprettyRedshiftProps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmyClusterProps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    315\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mClusterNotFoundFault\u001b[0m: An error occurred (ClusterNotFound) when calling the DescribeClusters operation: Cluster dwhcluster not found."
     ]
    }
   ],
   "source": [
    "myClusterProps = redshift.describe_clusters(ClusterIdentifier=DWH_CLUSTER_IDENTIFIER)['Clusters'][0]\n",
    "prettyRedshiftProps(myClusterProps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 7.2 Clean AWS IAM role/policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '354a79dc-6ba5-4638-a747-0612fe674cf2',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '354a79dc-6ba5-4638-a747-0612fe674cf2',\n",
       "   'content-type': 'text/xml',\n",
       "   'content-length': '200',\n",
       "   'date': 'Sun, 07 Jun 2020 16:44:02 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iam.detach_role_policy(RoleName=DWH_IAM_ROLE_NAME, PolicyArn=\"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\")\n",
    "iam.delete_role(RoleName=DWH_IAM_ROLE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
